{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## IMPORTANT !\n",
    "\n",
    "# In the first order need to set the number of CPU \n",
    "# for calculation before launching (depends on computer's number of cores)\n",
    "n_jobs= 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import glob\n",
    "import joblib\n",
    "import warnings\n",
    "from datetime import date, datetime\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import LeavePGroupsOut\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "import scipy.stats as st\n",
    "\n",
    "from nilearn import image as nli\n",
    "from nilearn import plotting\n",
    "\n",
    "#from mne.viz import plot_connectivity_circle\n",
    "from mne_connectivity.viz import plot_connectivity_circle\n",
    "\n",
    "\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "\n",
    "from scipy.stats import zscore as  zscore\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def control_2(z, control, index):    #age+gender+race/ethn == 4\n",
    "    #z should be a series\n",
    "    #control is a feature table\n",
    "    #index for indexing\n",
    "    \n",
    "    #shrink data to local train index\n",
    "    y = z.reindex(index = index)\n",
    "    X = control.reindex(index = index)\n",
    "\n",
    "    ind_y = np.array(y.index)\n",
    "    \n",
    "    #Centralize target by y_i-y_mean\n",
    "    y= pd.DataFrame([i-y.mean() for i in y], index=y.index)    \n",
    "    #y_real = y\n",
    "    \n",
    "    #reshaping data\n",
    "    if len(X.values.shape) == 1:\n",
    "        X = X.values.reshape(-1, 1)\n",
    "    else:\n",
    "        X = X.values\n",
    "    y = y.values.reshape(-1, 1).ravel()\n",
    "    \n",
    "    #fill Nan in X\n",
    "    X = SimpleImputer(strategy='mean').fit_transform(X)\n",
    "    \n",
    "    #Standartize X\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    #Fit to the training set\n",
    "    y_pred = LinearRegression().fit(X, y).predict(X)\n",
    "    \n",
    "    y_res = y - y_pred\n",
    "    \n",
    "    return y_res, ind_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def elnet(X, y):\n",
    "\n",
    "    #drop Nan in target and clean this subj from features\n",
    "    y = y.dropna()\n",
    "    X = X.reindex(index=y.index)\n",
    "    ind_y = np.array(y.index)\n",
    "      \n",
    "    y_real=y\n",
    "    \n",
    "    #reshaping data\n",
    "    X = X.values\n",
    "    y = y.values.reshape(-1, 1).ravel()\n",
    "    \n",
    "    #Standartize X\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    # Setup the pipeline steps:\n",
    "    steps = [('elasticnet', ElasticNet(random_state=42))]\n",
    "\n",
    "    # Create the pipeline: pipeline \n",
    "    pipeline = Pipeline(steps)\n",
    "\n",
    "    # Specify the hyperparameter space\n",
    "    parameters = {'elasticnet__alpha': np.logspace(-1, 2, 70),\n",
    "                  'elasticnet__l1_ratio':np.linspace(0,1,25)}\n",
    "\n",
    "    # Create the GridSearchCV object:\n",
    "    gm_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=n_jobs)\n",
    "    \n",
    "    # Fit to the training set\n",
    "    gm_cv.fit(X, y)\n",
    "    \n",
    "    #predict new y\n",
    "    y_pred = gm_cv.predict(X)\n",
    "\n",
    "    # Compute and print the metrics\n",
    "    acc = gm_cv.best_score_\n",
    "    bpar = gm_cv.best_params_\n",
    "    model = gm_cv.best_estimator_\n",
    "    mse = mean_squared_error(y_real, y_pred)\n",
    "    mae = mean_absolute_error(y_real, y_pred)\n",
    "    corr, _ = pearsonr(np.array(y_real.values.reshape(-1, 1).ravel(), dtype=float), np.array(y_pred, dtype=float))\n",
    "            \n",
    "    return bpar['elasticnet__alpha'], bpar['elasticnet__l1_ratio'], acc, mse, corr, model, y_pred, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def reaply_ElNet(X, y, model):\n",
    "    # param should be pd.Series with indexes from model\n",
    "    \n",
    "    #drop Nan in target and clean this subj from features\n",
    "    y = y.dropna()\n",
    "    X = X.reindex(index =y.index)\n",
    "    ind_y = np.array(y.index)  # indexes as separate variable \n",
    "    \n",
    "    y_real = y\n",
    "\n",
    "    #reshaping data\n",
    "    X = X.values\n",
    "    y = y.values.reshape(-1, 1).ravel()\n",
    "    \n",
    "    #Standartize X\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    #predict new y\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    # Compute and print the metrics\n",
    "    bacc = model.score(X, y)\n",
    "    mse = mean_squared_error(y_real, y_pred)\n",
    "    mae = mean_absolute_error(y_real, y_pred) \n",
    "    corr, _ = pearsonr(np.array(y_real.values.reshape(-1, 1).ravel(), dtype=float), np.array(y_pred, dtype=float))\n",
    "    \n",
    "    return y_pred, y_real, ind_y, bacc, mse, corr, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path to the tables folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path='/media/hcs-psy-narun/Alina/Lifespan_Projects_NonTask_Comparison/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load HCP YA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "#targets table\n",
    "targ_YA = pd.read_csv(path+'HCP_YA/'+'cognition_table.csv', index_col=0)['CogTotalComp_Unadj'].dropna()\n",
    "\n",
    "#demography\n",
    "demo_YA = pd.read_csv(path+'HCP_YA/'+'demographics_table.csv', index_col=0)\n",
    "demo_YA = demo_YA.reindex(index=targ_YA.index) #filter subjects to target subj length\n",
    "\n",
    "#features tables as dictionary\n",
    "features_YA = {\n",
    "    'cort':pd.read_csv(path+'HCP_YA/'+'cort_table.csv', index_col=0),\n",
    "    'subc':pd.read_csv(path+'HCP_YA/'+'subc_table.csv', index_col=0),\n",
    "    'surf':pd.read_csv(path+'HCP_YA/'+'surf_table.csv', index_col=0),\n",
    "    'volBrain':pd.read_csv(path+'HCP_YA/'+'VolBrain_table.csv', index_col=0),\n",
    "    'rest':pd.read_csv(path+'HCP_YA/'+'Rest_FC_group_z_full.csv', index_col=0)}\n",
    "\n",
    "#filter to target subject number\n",
    "for key in features_YA.keys():\n",
    "    features_YA[key] = features_YA[key].reindex(index=targ_YA.index)\n",
    "\n",
    "#rename columns for cort and area\n",
    "for mod in ['cort', 'surf']:\n",
    "    features_YA[mod].columns = [mod+'_'+i for i in features_YA[mod].columns]\n",
    "\n",
    "#create tables with 2 controling parameters: age, sex\n",
    "sex_coded = pd.Series(LabelEncoder().fit_transform(demo_YA.loc[:,['Gender']]), index=demo_YA.index, name='Gender')\n",
    "\n",
    "control_YA = pd.concat([sex_coded, demo_YA.loc[:, ['Age_in_Yrs']]], axis=1) #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load HCP A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "#targets table\n",
    "targ_A = pd.read_csv(path+'HCP_A/'+'cognition.csv', index_col=0)['nih_totalcogcomp_unadjusted'].dropna()\n",
    "\n",
    "#demography\n",
    "demo_A = pd.read_csv(path+'HCP_A/'+'demography.csv', index_col=0)\n",
    "demo_A = demo_A.reindex(index=targ_A.index) #filter subjects to target subj length\n",
    "\n",
    "#features tables as dictionary\n",
    "features_A = {\n",
    "    'cort':pd.read_csv(path+'HCP_A/'+'cort.csv', index_col=0),\n",
    "    'subc':pd.read_csv(path+'HCP_A/'+'subc.csv', index_col=0),\n",
    "    'surf':pd.read_csv(path+'HCP_A/'+'surf.csv', index_col=0),\n",
    "    'volBrain':pd.read_csv(path+'HCP_A/'+'VolBrain.csv', index_col=0),\n",
    "    'rest':pd.read_csv(path+'HCP_A/'+'rest_hpass.csv', index_col=0)}\n",
    "\n",
    "#filter to target subject number\n",
    "for key in features_A.keys():\n",
    "    features_A[key] = features_A[key].reindex(index=targ_A.index)\n",
    "\n",
    "#rename columns for cort and area\n",
    "for mod in ['cort', 'surf']:\n",
    "    features_A[mod].columns = [mod+'_'+i for i in features_A[mod].columns]\n",
    "\n",
    "#create tables with 2 controling parameters: age, sex\n",
    "sex_coded = pd.Series(LabelEncoder().fit_transform(demo_A.loc[:,['sex']]), index=demo_A.index, name='sex')\n",
    "\n",
    "control_A = pd.concat([sex_coded, (demo_A.loc[:, ['interview_age']]) ], axis=1) #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load DUD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "#targets table\n",
    "targ_D = pd.read_csv(path+'DUD_45/'+'info.csv', index_col=0)['fsiq45'].dropna()\n",
    "\n",
    "#demography\n",
    "demo_D = pd.read_csv(path+'DUD_45/'+'info.csv', index_col=0)['sex']\n",
    "demo_D = demo_D.reindex(index=targ_D.index) #filter subjects to target subj length\n",
    "\n",
    "#features tables as dictionary\n",
    "features_D = {\n",
    "    'cort':pd.read_csv(path+'DUD_45/'+'cort_thck.csv', index_col=0),\n",
    "    'subc':pd.read_csv(path+'DUD_45/'+'subc_vol.csv', index_col=0),\n",
    "    'surf':pd.read_csv(path+'DUD_45/'+'cort_area.csv', index_col=0),\n",
    "    'volBrain':pd.read_csv(path+'DUD_45/'+'total_vol.csv', index_col=0),\n",
    "    'rest':pd.read_csv(path+'DUD_45/'+'rest.csv', index_col=0)}\n",
    "\n",
    "#filter to target subject number\n",
    "for key in features_D.keys():\n",
    "    features_D[key] = features_D[key].reindex(index=targ_D.index)\n",
    "\n",
    "#rename columns for cort and area\n",
    "for mod in ['cort', 'surf']:\n",
    "    features_D[mod].columns = [mod+'_'+i for i in features_D[mod].columns]\n",
    "\n",
    "#create tables with 2 controling parameters: age, sex\n",
    "sex_coded = pd.Series(LabelEncoder().fit_transform(demo_D), index=demo_D.index, name='sex')\n",
    "\n",
    "control_D = sex_coded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the same labels for columns in HCP YA and HCP A\n",
    "features_YA['rest'].columns = features_A['rest'].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "##### Adjust the brain features (age, sex, etc, depends on control table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "controlling  cort 2023-09-29 23:12:51.939739\n",
      "controlling  subc 2023-09-29 23:12:54.466511\n",
      "controlling  surf 2023-09-29 23:12:54.795880\n",
      "controlling  volBrain 2023-09-29 23:12:57.302943\n",
      "controlling  rest 2023-09-29 23:12:57.394094\n",
      "controlling  cort 2023-09-29 23:33:25.427101\n",
      "controlling  subc 2023-09-29 23:33:27.012377\n",
      "controlling  surf 2023-09-29 23:33:27.214079\n",
      "controlling  volBrain 2023-09-29 23:33:28.777552\n",
      "controlling  rest 2023-09-29 23:33:28.834133\n",
      "controlling  cort 2023-09-29 23:45:51.053109\n",
      "controlling  subc 2023-09-29 23:45:53.356113\n",
      "controlling  surf 2023-09-29 23:45:53.656907\n",
      "controlling  volBrain 2023-09-29 23:45:56.059686\n",
      "controlling  rest 2023-09-29 23:45:56.139268\n"
     ]
    }
   ],
   "source": [
    "#control modalities \n",
    "\n",
    "Features = {}\n",
    "for features, targ, control, dset in zip([features_YA, features_A, features_D], \n",
    "                                         [targ_YA, targ_A, targ_D], \n",
    "                                         [control_YA, control_A, control_D], \n",
    "                                         ['YA', 'A', 'D']):\n",
    "    Features[dset] = {}\n",
    "    Features[dset]['features_res'] = {}\n",
    "    Features[dset]['targ'] = {}\n",
    "    Features[dset]['model_PCA'] = {}\n",
    "    \n",
    "    #control target\n",
    "    p1, p2 = control_2(targ, control, targ.index)\n",
    "    targ = zscore(pd.Series(p1, index = p2))      #zscore\n",
    "\n",
    "    #control modalities\n",
    "    features_res = {}\n",
    "    for key in features.keys():\n",
    "        print('controlling ', key, datetime.now())\n",
    "\n",
    "        #controlling the remaining for 2 parameters (age+sex)\n",
    "        if key in ['cort', 'surf', 'subc', 'volBrain',  'rest']:\n",
    "            d = {}\n",
    "            for col in features[key].columns:\n",
    "                p1,p2 = control_2(features[key][col], control, targ.index)\n",
    "                d[col] = p1\n",
    "            df= pd.DataFrame(d, index = p2)\n",
    "            features_res[key] = zscore(df)   #zscore\n",
    "\n",
    "\n",
    "    #keep rest residuals as a separate var\n",
    "    res_rest = features_res['rest']\n",
    "    res_rest_st = pd.DataFrame((StandardScaler().fit_transform(res_rest)), \n",
    "                                  index=res_rest.index, columns=res_rest.columns)\n",
    "\n",
    "    #apply PCA to resting state\n",
    "    pca = PCA(n_components=75, random_state=11)\n",
    "    pca.fit(res_rest_st.values)\n",
    "    rest_pca1 = pd.DataFrame(pca.transform(res_rest_st.values), index=res_rest.index)\n",
    "\n",
    "    #assign pca table to rest features\n",
    "    features_res['rest_PCA'] = rest_pca1\n",
    "    \n",
    "\n",
    "    \n",
    "    Features[dset]['features_res'] = features_res\n",
    "    Features[dset]['targ'] = targ\n",
    "    Features[dset]['model_PCA'] = pca\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "873\n",
      "504\n",
      "754\n"
     ]
    }
   ],
   "source": [
    "#check numbers\n",
    "for tg in [targ_YA, targ_A, targ_D]:\n",
    "    print(len(tg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.mkdir(path+'output_3dsets_stack_newREST')\n",
    "path_out = path+'output_3dsets_stack_newREST/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.mkdir(path_out+'PCA_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key in Features.keys():\n",
    "    joblib.dump(Features[key]['model_PCA'], (path_out+'PCA_models'+'/rest_'+key+'_pca_model.sav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YA\n",
      "start  cort 2023-09-30 00:03:51.782071\n",
      "start  subc 2023-09-30 00:04:05.084574\n",
      "start  surf 2023-09-30 00:04:14.101919\n",
      "start  volBrain 2023-09-30 00:04:24.198526\n",
      "start  rest_PCA 2023-09-30 00:04:32.722565\n",
      "start  stack 2023-09-30 00:04:41.926542\n",
      "start  Test_1 2023-09-30 00:04:51.148789\n",
      "start  Test_2 2023-09-30 00:04:51.278026\n",
      "A\n",
      "start  cort 2023-09-30 00:04:51.461976\n",
      "start  subc 2023-09-30 00:05:00.748794\n",
      "start  surf 2023-09-30 00:05:09.413521\n",
      "start  volBrain 2023-09-30 00:05:18.819790\n",
      "start  rest_PCA 2023-09-30 00:05:29.345604\n",
      "start  stack 2023-09-30 00:05:38.309323\n",
      "start  Test_1 2023-09-30 00:05:46.345012\n",
      "start  Test_2 2023-09-30 00:05:46.535314\n",
      "D\n",
      "start  cort 2023-09-30 00:05:46.718837\n",
      "start  subc 2023-09-30 00:05:57.854155\n",
      "start  surf 2023-09-30 00:06:06.539581\n",
      "start  volBrain 2023-09-30 00:06:22.953347\n",
      "start  rest_PCA 2023-09-30 00:06:31.553851\n",
      "start  stack 2023-09-30 00:06:40.569015\n",
      "start  Test_1 2023-09-30 00:06:48.899783\n",
      "start  Test_2 2023-09-30 00:06:49.092783\n"
     ]
    }
   ],
   "source": [
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "\n",
    "i=0\n",
    "\n",
    "Outputs = {}\n",
    "\n",
    "for KEY in list(Features.keys()):\n",
    "    print(KEY)    \n",
    "    oth = list(Features.keys())\n",
    "    oth.remove(KEY)\n",
    "    \n",
    "    Outputs[KEY]={}\n",
    "    \n",
    "    #assign train and test\n",
    "    Train = Features[KEY]\n",
    "    Test1 = Features[oth[0]]\n",
    "    Test2 = Features[oth[1]]\n",
    "    \n",
    "    \n",
    "    ###### part 1: TRAIN \n",
    "    \n",
    "    Outputs[KEY]['Train']={}\n",
    "\n",
    "    \n",
    "    #Launch ElasticNet\n",
    "    dict_perf={}        #to store modality performans\n",
    "    dict_elnet_model={}  #to store enet model\n",
    "    dict_ypred={}       #to store predicted values\n",
    "\n",
    "    for key in Train['features_res'].keys():\n",
    "        \n",
    "        if key != 'rest':\n",
    "            \n",
    "            print('start ', str(key), datetime.now())   #print start time of calculations\n",
    "            \n",
    "            bpar1, bpar2, acc, mse, corr, model, y_pred, mae = elnet(Train['features_res'][key], \n",
    "                                                                     Train['targ']) #ML\n",
    "        \n",
    "            dict_perf[key] = acc, mse, mae, corr, bpar1, bpar2 \n",
    "            dict_elnet_model[key] = model\n",
    "            dict_ypred[key] = y_pred\n",
    "    \n",
    "    #run separatelly for stack\n",
    "    \n",
    "    print('start ', 'stack', datetime.now())   #print start time of calculations\n",
    "    \n",
    "    #table with predicted values\n",
    "    stack_tab = pd.DataFrame(dict_ypred, index=Train['targ'].index)\n",
    "    \n",
    "    stack_STD_model = StandardScaler().fit(stack_tab.values)\n",
    "    \n",
    "    stack_tab_std = pd.DataFrame(stack_STD_model.transform(stack_tab.values), \n",
    "                                 index=stack_tab.index, columns=stack_tab.columns)\n",
    "            \n",
    "    bpar1, bpar2, acc, mse, corr, model, y_pred, mae = elnet(stack_tab_std, Train['targ']) #ML\n",
    "        \n",
    "    dict_perf['stack'] = acc, mse, mae, corr, bpar1, bpar2 \n",
    "    dict_elnet_model['stack'] = model\n",
    "    dict_ypred['stack'] = y_pred\n",
    "    \n",
    "        \n",
    "    df_perf = pd.DataFrame(dict_perf, index=['best score r2', 'mse', 'mae','corr', 'best alpha', 'best l1_ratio'])\n",
    "    df_y_pred = pd.DataFrame(dict_ypred, index=Train['targ'].index) \n",
    "    df_y_pred['origin_y'] = Train['targ']\n",
    "    \n",
    "    Outputs[KEY]['Train']['performance'] = df_perf\n",
    "    Outputs[KEY]['Train']['y_pred'] = df_y_pred\n",
    "    Outputs[KEY]['Train']['models'] = dict_elnet_model\n",
    "    Outputs[KEY]['Train']['stack_tab'] = stack_tab\n",
    "    Outputs[KEY]['Train']['stack_tab_std'] = stack_tab_std\n",
    "    Outputs[KEY]['Train']['stack_STD_model'] = stack_STD_model\n",
    "    \n",
    "    ###### part 2: TEST\n",
    "    \n",
    "    j=1\n",
    "    for Test in [Test1, Test2]:\n",
    "        \n",
    "        print('start ', 'Test'+'_'+str(j), datetime.now()) \n",
    "        \n",
    "        Outputs[KEY]['Test'+'_'+str(j)]={}\n",
    "        \n",
    "        #apply PCA from Train\n",
    "        \n",
    "        #apply PCA to resting state\n",
    "        rest_pca = pd.DataFrame(Train['model_PCA'].transform(Test['features_res']['rest'].values), \n",
    "                                index=Test['features_res']['rest'].index)\n",
    "\n",
    "        \n",
    "        \n",
    "        #apply trained Enet models\n",
    "        \n",
    "        dict_perf={}        #to store modality performans\n",
    "        dict_ypred={}\n",
    "        \n",
    "        for key in list(Test['features_res'].keys()):\n",
    "            \n",
    "            if key!='rest' and key!='rest_PCA':\n",
    "                                           \n",
    "                y_pred, y_real, ind_y, bacc, mse, corr, mae = reaply_ElNet(Test['features_res'][key], \n",
    "                                                                           Test['targ'], \n",
    "                                                                           Outputs[KEY]['Train']['models'][key]) #ML\n",
    "                dict_ypred[key] = y_pred\n",
    "                dict_perf[key] = bacc, mse, mae, corr\n",
    "                \n",
    "        #run separatelly for test pca and stack\n",
    "        for key in ['rest_PCA', 'stack']:\n",
    "            \n",
    "            if key == 'rest_PCA':\n",
    "                \n",
    "                feat = rest_pca\n",
    "                \n",
    "                y_pred, y_real, ind_y, bacc, mse, corr, mae = reaply_ElNet(feat,\n",
    "                                                                           Test['targ'],\n",
    "                                                                           Outputs[KEY]['Train']['models'][key]) #ML\n",
    "                \n",
    "                dict_ypred[key] = y_pred\n",
    "                dict_perf[key] = bacc, mse, mae, corr\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                #table with pred-values\n",
    "                stack_test = pd.DataFrame(dict_ypred, index = Test['targ'].index)\n",
    "                \n",
    "                stack_test_std = pd.DataFrame(stack_STD_model.transform(stack_test.values),\n",
    "                                              index=stack_test.index, columns=stack_test.columns)\n",
    "                \n",
    "                y_pred, y_real, ind_y, bacc, mse, corr, mae = reaply_ElNet(stack_test_std,\n",
    "                                                                           Test['targ'],\n",
    "                                                                           Outputs[KEY]['Train']['models'][key]) #ML\n",
    "                \n",
    "                dict_ypred[key] = y_pred\n",
    "                dict_perf[key] = bacc, mse, mae, corr\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        df_perf = pd.DataFrame(dict_perf, index=['best score r2', 'mse', 'mae','corr'])\n",
    "        df_ypred = pd.DataFrame(dict_ypred, index=Test['targ'].index)\n",
    "        df_ypred['origin_y'] = Test['targ']\n",
    "        \n",
    "        Outputs[KEY]['Test'+'_'+str(j)]['performance'] = df_perf\n",
    "        Outputs[KEY]['Test'+'_'+str(j)]['y_pred'] = df_ypred\n",
    "        Outputs[KEY]['Test'+'_'+str(j)]['dset'] = oth[j-1]\n",
    "        Outputs[KEY]['Test'+'_'+str(j)]['stack_tab'] = stack_test\n",
    "        Outputs[KEY]['Test'+'_'+str(j)]['stack_test_std'] = stack_test_std\n",
    "        Outputs[KEY]['Test'+'_'+str(j)]['rest_PCA'] = rest_pca\n",
    "        \n",
    "        \n",
    "        j+=1\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### save features and  results\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(path_out+'Features.pkl', 'wb') as handle:\n",
    "    pickle.dump(Features, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(path_out+'Outputs.pkl', 'wb') as handle:\n",
    "    pickle.dump(Outputs, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset  YA  as TRAIN\n",
      " \n",
      "Test 1, Dataset  A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cort</th>\n",
       "      <th>subc</th>\n",
       "      <th>surf</th>\n",
       "      <th>volBrain</th>\n",
       "      <th>rest_PCA</th>\n",
       "      <th>stack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>best score r2</th>\n",
       "      <td>0.043808</td>\n",
       "      <td>0.069221</td>\n",
       "      <td>0.031504</td>\n",
       "      <td>0.042935</td>\n",
       "      <td>0.080683</td>\n",
       "      <td>0.117003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mse</th>\n",
       "      <td>0.956192</td>\n",
       "      <td>0.930779</td>\n",
       "      <td>0.968496</td>\n",
       "      <td>0.957065</td>\n",
       "      <td>0.919317</td>\n",
       "      <td>0.882997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>0.787604</td>\n",
       "      <td>0.778418</td>\n",
       "      <td>0.796823</td>\n",
       "      <td>0.784424</td>\n",
       "      <td>0.765129</td>\n",
       "      <td>0.752249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corr</th>\n",
       "      <td>0.228624</td>\n",
       "      <td>0.286252</td>\n",
       "      <td>0.191306</td>\n",
       "      <td>0.207227</td>\n",
       "      <td>0.284121</td>\n",
       "      <td>0.358577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   cort      subc      surf  volBrain  rest_PCA     stack\n",
       "best score r2  0.043808  0.069221  0.031504  0.042935  0.080683  0.117003\n",
       "mse            0.956192  0.930779  0.968496  0.957065  0.919317  0.882997\n",
       "mae            0.787604  0.778418  0.796823  0.784424  0.765129  0.752249\n",
       "corr           0.228624  0.286252  0.191306  0.207227  0.284121  0.358577"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Test 2, Dataset  D\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cort</th>\n",
       "      <th>subc</th>\n",
       "      <th>surf</th>\n",
       "      <th>volBrain</th>\n",
       "      <th>rest_PCA</th>\n",
       "      <th>stack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>best score r2</th>\n",
       "      <td>-0.009049</td>\n",
       "      <td>0.047533</td>\n",
       "      <td>0.023122</td>\n",
       "      <td>0.075002</td>\n",
       "      <td>0.047376</td>\n",
       "      <td>0.039155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mse</th>\n",
       "      <td>1.009049</td>\n",
       "      <td>0.952467</td>\n",
       "      <td>0.976878</td>\n",
       "      <td>0.924998</td>\n",
       "      <td>0.952624</td>\n",
       "      <td>0.960845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>0.805389</td>\n",
       "      <td>0.779181</td>\n",
       "      <td>0.787158</td>\n",
       "      <td>0.762989</td>\n",
       "      <td>0.774022</td>\n",
       "      <td>0.774610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corr</th>\n",
       "      <td>0.028215</td>\n",
       "      <td>0.226428</td>\n",
       "      <td>0.168746</td>\n",
       "      <td>0.284097</td>\n",
       "      <td>0.221023</td>\n",
       "      <td>0.253031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   cort      subc      surf  volBrain  rest_PCA     stack\n",
       "best score r2 -0.009049  0.047533  0.023122  0.075002  0.047376  0.039155\n",
       "mse            1.009049  0.952467  0.976878  0.924998  0.952624  0.960845\n",
       "mae            0.805389  0.779181  0.787158  0.762989  0.774022  0.774610\n",
       "corr           0.028215  0.226428  0.168746  0.284097  0.221023  0.253031"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      "Dataset  A  as TRAIN\n",
      " \n",
      "Test 1, Dataset  YA\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cort</th>\n",
       "      <th>subc</th>\n",
       "      <th>surf</th>\n",
       "      <th>volBrain</th>\n",
       "      <th>rest_PCA</th>\n",
       "      <th>stack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>best score r2</th>\n",
       "      <td>-0.001000</td>\n",
       "      <td>0.045196</td>\n",
       "      <td>0.057380</td>\n",
       "      <td>0.053086</td>\n",
       "      <td>0.006139</td>\n",
       "      <td>-0.015825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mse</th>\n",
       "      <td>1.001000</td>\n",
       "      <td>0.954804</td>\n",
       "      <td>0.942620</td>\n",
       "      <td>0.946914</td>\n",
       "      <td>0.993861</td>\n",
       "      <td>1.015825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>0.810500</td>\n",
       "      <td>0.798428</td>\n",
       "      <td>0.795082</td>\n",
       "      <td>0.791231</td>\n",
       "      <td>0.800840</td>\n",
       "      <td>0.806973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corr</th>\n",
       "      <td>0.139836</td>\n",
       "      <td>0.213061</td>\n",
       "      <td>0.239941</td>\n",
       "      <td>0.231887</td>\n",
       "      <td>0.206581</td>\n",
       "      <td>0.290697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   cort      subc      surf  volBrain  rest_PCA     stack\n",
       "best score r2 -0.001000  0.045196  0.057380  0.053086  0.006139 -0.015825\n",
       "mse            1.001000  0.954804  0.942620  0.946914  0.993861  1.015825\n",
       "mae            0.810500  0.798428  0.795082  0.791231  0.800840  0.806973\n",
       "corr           0.139836  0.213061  0.239941  0.231887  0.206581  0.290697"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Test 2, Dataset  D\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cort</th>\n",
       "      <th>subc</th>\n",
       "      <th>surf</th>\n",
       "      <th>volBrain</th>\n",
       "      <th>rest_PCA</th>\n",
       "      <th>stack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>best score r2</th>\n",
       "      <td>-0.029258</td>\n",
       "      <td>0.042802</td>\n",
       "      <td>0.001720</td>\n",
       "      <td>0.082447</td>\n",
       "      <td>-0.006140</td>\n",
       "      <td>-0.118778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mse</th>\n",
       "      <td>1.029258</td>\n",
       "      <td>0.957198</td>\n",
       "      <td>0.998280</td>\n",
       "      <td>0.917553</td>\n",
       "      <td>1.006140</td>\n",
       "      <td>1.118778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>0.811239</td>\n",
       "      <td>0.779492</td>\n",
       "      <td>0.793407</td>\n",
       "      <td>0.760077</td>\n",
       "      <td>0.800571</td>\n",
       "      <td>0.846465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corr</th>\n",
       "      <td>0.085084</td>\n",
       "      <td>0.207294</td>\n",
       "      <td>0.111171</td>\n",
       "      <td>0.306955</td>\n",
       "      <td>0.172207</td>\n",
       "      <td>0.195772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   cort      subc      surf  volBrain  rest_PCA     stack\n",
       "best score r2 -0.029258  0.042802  0.001720  0.082447 -0.006140 -0.118778\n",
       "mse            1.029258  0.957198  0.998280  0.917553  1.006140  1.118778\n",
       "mae            0.811239  0.779492  0.793407  0.760077  0.800571  0.846465\n",
       "corr           0.085084  0.207294  0.111171  0.306955  0.172207  0.195772"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      "Dataset  D  as TRAIN\n",
      " \n",
      "Test 1, Dataset  YA\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cort</th>\n",
       "      <th>subc</th>\n",
       "      <th>surf</th>\n",
       "      <th>volBrain</th>\n",
       "      <th>rest_PCA</th>\n",
       "      <th>stack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>best score r2</th>\n",
       "      <td>-0.025379</td>\n",
       "      <td>0.018766</td>\n",
       "      <td>0.024264</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.051982</td>\n",
       "      <td>-0.016920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mse</th>\n",
       "      <td>1.025379</td>\n",
       "      <td>0.981234</td>\n",
       "      <td>0.975736</td>\n",
       "      <td>0.964800</td>\n",
       "      <td>0.948018</td>\n",
       "      <td>1.016920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>0.822247</td>\n",
       "      <td>0.806483</td>\n",
       "      <td>0.802232</td>\n",
       "      <td>0.801480</td>\n",
       "      <td>0.783472</td>\n",
       "      <td>0.799807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corr</th>\n",
       "      <td>0.036593</td>\n",
       "      <td>0.160045</td>\n",
       "      <td>0.178881</td>\n",
       "      <td>0.201263</td>\n",
       "      <td>0.233578</td>\n",
       "      <td>0.236469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   cort      subc      surf  volBrain  rest_PCA     stack\n",
       "best score r2 -0.025379  0.018766  0.024264  0.035200  0.051982 -0.016920\n",
       "mse            1.025379  0.981234  0.975736  0.964800  0.948018  1.016920\n",
       "mae            0.822247  0.806483  0.802232  0.801480  0.783472  0.799807\n",
       "corr           0.036593  0.160045  0.178881  0.201263  0.233578  0.236469"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Test 2, Dataset  A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cort</th>\n",
       "      <th>subc</th>\n",
       "      <th>surf</th>\n",
       "      <th>volBrain</th>\n",
       "      <th>rest_PCA</th>\n",
       "      <th>stack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>best score r2</th>\n",
       "      <td>-0.004504</td>\n",
       "      <td>0.033447</td>\n",
       "      <td>-0.020795</td>\n",
       "      <td>0.038386</td>\n",
       "      <td>-0.009307</td>\n",
       "      <td>-0.074229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mse</th>\n",
       "      <td>1.004504</td>\n",
       "      <td>0.966553</td>\n",
       "      <td>1.020795</td>\n",
       "      <td>0.961614</td>\n",
       "      <td>1.009307</td>\n",
       "      <td>1.074229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>0.809268</td>\n",
       "      <td>0.789476</td>\n",
       "      <td>0.815155</td>\n",
       "      <td>0.788838</td>\n",
       "      <td>0.801066</td>\n",
       "      <td>0.828596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corr</th>\n",
       "      <td>0.091103</td>\n",
       "      <td>0.192780</td>\n",
       "      <td>0.103317</td>\n",
       "      <td>0.206388</td>\n",
       "      <td>0.122358</td>\n",
       "      <td>0.166632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   cort      subc      surf  volBrain  rest_PCA     stack\n",
       "best score r2 -0.004504  0.033447 -0.020795  0.038386 -0.009307 -0.074229\n",
       "mse            1.004504  0.966553  1.020795  0.961614  1.009307  1.074229\n",
       "mae            0.809268  0.789476  0.815155  0.788838  0.801066  0.828596\n",
       "corr           0.091103  0.192780  0.103317  0.206388  0.122358  0.166632"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "### show prediction accuracy indexes\n",
    "\n",
    "for KEY in list(Outputs.keys()):\n",
    "    print('Dataset ', KEY, ' as TRAIN')\n",
    "    #print('Train')\n",
    "    #display(Outputs[KEY]['Train']['performance'].iloc[:-2,:])\n",
    "    print(' ')\n",
    "    \n",
    "    print('Test 1, Dataset ', Outputs[KEY]['Test_1']['dset'])\n",
    "    display(Outputs[KEY]['Test_1']['performance'])\n",
    "    print(' ')\n",
    "    \n",
    "    print('Test 2, Dataset ', Outputs[KEY]['Test_2']['dset'])\n",
    "    display(Outputs[KEY]['Test_2']['performance'])\n",
    "    print(' ')\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load data (deserialize)\n",
    "#with open('filename.pickle', 'rb') as handle:\n",
    "#    unserialized_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
